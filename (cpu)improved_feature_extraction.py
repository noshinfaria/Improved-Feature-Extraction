# -*- coding: utf-8 -*-
"""(CPU)Improved Feature Extraction

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1-BAt-bhQcV72qE3Fm0L2DLDkdVQaS0lc
"""

from google.colab import drive
drive.mount('/content/drive')

from sklearn.metrics import roc_curve, auc
import numpy as np
import matplotlib.pyplot as plt

def compute_metrics(y_true, y_scores):
    # Compute ROC curve
    fpr, tpr, thresholds = roc_curve(y_true, y_scores)
    roc_auc = auc(fpr, tpr)

    # Compute Equal Error Rate (EER)
    fnr = 1 - tpr
    eer_threshold = thresholds[np.nanargmin(np.absolute(fnr - fpr))]
    eer = fpr[np.nanargmin(np.absolute(fnr - fpr))]

    # Compute True Acceptance Rate (TAR) at a common threshold (e.g., 0.5)
    tar = tpr[np.argmin(np.abs(thresholds - 0.5))]

    # Compute False Acceptance Rate (FAR) at the same threshold
    far = fpr[np.argmin(np.abs(thresholds - 0.5))]

    print(f"AUC: {roc_auc:.4f}")
    print(f"Equal Error Rate (EER): {eer:.4f} at threshold {eer_threshold:.4f}")
    print(f"True Acceptance Rate (TAR) at threshold 0.5: {tar:.4f}")
    print(f"False Acceptance Rate (FAR) at threshold 0.5: {far:.4f}")

    # Plot ROC curve
    plt.figure(figsize=(8, 6))
    plt.plot(fpr, tpr, label=f'ROC curve (area = {roc_auc:.2f}')
    plt.plot([0, 1], [0, 1], 'k--')
    plt.xlabel('False Positive Rate')
    plt.ylabel('True Positive Rate')
    plt.title('Receiver Operating Characteristic (ROC) Curve')
    plt.legend(loc='lower right')
    plt.show()

    # Plot FAR vs TAR
    plt.figure(figsize=(8, 6))
    plt.plot(thresholds, tpr, label='True Acceptance Rate')
    plt.plot(thresholds, fpr, label='False Acceptance Rate')
    plt.xlabel('Threshold')
    plt.ylabel('Rate')
    plt.title('False Acceptance Rate vs True Acceptance Rate')
    plt.legend()
    plt.grid()
    plt.show()

    return tar, far, eer, roc_auc

import os
import cv2
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, Lambda, Flatten
from tensorflow.keras.applications import VGG16
from tensorflow.keras import backend as K
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.callbacks import ModelCheckpoint
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns


# Step 1: Preprocess Image and Extract SIFT Features
def preprocess_image(image_path):
    # Load image in grayscale
    sift = cv2.SIFT_create()
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    img = cv2.resize(img, (224, 224))  # Resize to 224x224

    # Enhance image contrast
    img = cv2.convertScaleAbs(img, alpha=1.5, beta=0)  # Contrast control and brightness adjustment

    # Detect keypoints and compute descriptors using SIFT
    keypoints, descriptors = sift.detectAndCompute(img, None)
    if descriptors is None:
        descriptors = np.zeros((1, 128))  # Handle cases with no descriptors

    # Normalize pixel values
    img = img / 255.0
    return img, descriptors

# Step 2: Extract CNN Features using Pretrained Model
def extract_cnn_features(image, model):
    # Add batch and channel dimensions, and normalize image
    image_expanded = np.expand_dims(image, axis=(0, -1))
    image_expanded = np.repeat(image_expanded, 3, axis=-1)  # Repeat grayscale to 3 channels
    features = model.predict(image_expanded)
    return features.flatten()

# Step 3: Combine SIFT and CNN Features
def combine_features(sift_features, cnn_features):
    # Aggregate SIFT descriptors and normalize
    sift_features_mean = np.mean(sift_features, axis=0)
    scaler = StandardScaler()
    sift_features_normalized = scaler.fit_transform([sift_features_mean])

    # Concatenate SIFT and CNN features
    combined_features = np.hstack((sift_features_normalized.flatten(), cnn_features))
    return combined_features

def load_image_pairs_with_split(image_dir, pairs_file, model, test_size=0.2, val_size=0.1):
    pairs = pd.read_csv(pairs_file)
    image_a, image_b, labels = [], [], []

    for idx, row in pairs.iterrows():
        print(f"Processing pair {idx + 1}/{len(pairs)}")
        img_a_path = os.path.join(image_dir, row["image_a"])
        img_b_path = os.path.join(image_dir, row["image_b"])

        # Preprocess images and extract SIFT + CNN features
        img_a, sift_a = preprocess_image(img_a_path)
        img_b, sift_b = preprocess_image(img_b_path)

        cnn_a = extract_cnn_features(img_a, model)
        cnn_b = extract_cnn_features(img_b, model)

        combined_a = combine_features(sift_a, cnn_a)
        combined_b = combine_features(sift_b, cnn_b)

        image_a.append(combined_a)
        image_b.append(combined_b)
        labels.append(row["label"])

    # Convert to numpy arrays
    image_a = np.array(image_a)
    image_b = np.array(image_b)
    labels = np.array(labels)

    # Split into train, validation, and test sets
    X_train_a, X_temp_a, X_train_b, X_temp_b, y_train, y_temp = train_test_split(
        image_a, image_b, labels, test_size=test_size, random_state=42
    )
    val_split = val_size / (1 - test_size)  # Adjust val split based on remaining data
    X_val_a, X_test_a, X_val_b, X_test_b, y_val, y_test = train_test_split(
        X_temp_a, X_temp_b, y_temp, test_size=val_split, random_state=42
    )

    return X_train_a, X_train_b, y_train, X_val_a, X_val_b, y_val, X_test_a, X_test_b, y_test

# Step 5: Build Siamese Network
def siamese_network(input_shape):
    input_1 = Input(shape=input_shape)
    input_2 = Input(shape=input_shape)

    # Shared dense layers
    shared_dense = Dense(256, activation='relu')
    processed_1 = shared_dense(input_1)
    processed_2 = shared_dense(input_2)

    # Compute absolute difference
    distance = Lambda(lambda tensors: K.abs(tensors[0] - tensors[1]))([processed_1, processed_2])
    output = Dense(1, activation='sigmoid')(distance)

    # Build model
    model = Model(inputs=[input_1, input_2], outputs=output)
    return model

# Load Pretrained CNN (VGG16 as an example)
vgg_model = VGG16(weights='imagenet', include_top=False)
cnn_feature_extractor = Model(inputs=vgg_model.input, outputs=Flatten()(vgg_model.output))

# Paths
image_dir = "/content/drive/MyDrive/Faria/fingerprint/dataset/pair_data_extreme(geo trans)"
pairs_file = "/content/drive/MyDrive/Faria/fingerprint/dataset/fingerprint_pairs_extreme(geo_trans).csv"

# Load and preprocess data with train-val-test split
(
    X_train_a, X_train_b, y_train,
    X_val_a, X_val_b, y_val,
    X_test_a, X_test_b, y_test
) = load_image_pairs_with_split(image_dir, pairs_file, cnn_feature_extractor)

# Step 6: Train Siamese Network
input_shape = X_train_a[0].shape
siamese_model = siamese_network(input_shape)
siamese_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Define ModelCheckpoint to save the best model
checkpoint_path = "/content/drive/MyDrive/Faria/fingerprint/models/feature_extraction_siamese_model_best.keras"
checkpoint = ModelCheckpoint(
    checkpoint_path, monitor='val_accuracy', save_best_only=True, mode='max', verbose=1
)

# Train the model
history = siamese_model.fit(
    [X_train_a, X_train_b], y_train,
    validation_data=([X_val_a, X_val_b], y_val),
    epochs=10,
    batch_size=32,
    callbacks=[checkpoint]
)

# Plot training and validation accuracy
import matplotlib.pyplot as plt

plt.figure(figsize=(10, 5))
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Step 7: Evaluate
# Load the best model
siamese_model.load_weights(checkpoint_path)

test_loss, test_accuracy = siamese_model.evaluate([X_test_a, X_test_b], y_test)
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")

# Get model predictions on test data
y_scores = siamese_model.predict([X_test_a, X_test_b]).ravel()

# Compute and display metrics
tar, far, eer, roc_auc = compute_metrics(y_test, y_scores)

# Convert probabilities to binary predictions
y_pred = (y_scores >= 0.5).astype(int)

# Compute confusion matrix
cm = confusion_matrix(y_test, y_pred)

# Plot confusion matrix
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Imposter", "Genuine"], yticklabels=["Imposter", "Genuine"])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

# Print classification report
print(classification_report(y_test, y_pred, target_names=["Imposter", "Genuine"]))

"""# **CNN based Feature Extraction**"""

import os
import cv2
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, Lambda, Flatten
from tensorflow.keras.applications import VGG16
from tensorflow.keras import backend as K
from sklearn.model_selection import train_test_split
from tensorflow.keras.callbacks import ModelCheckpoint
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt

# Step 1: Preprocess Image

def preprocess_image(image_path):
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    img = cv2.resize(img, (224, 224))  # Resize to 224x224
    img = np.expand_dims(img, axis=-1)  # Add channel dimension
    img = np.repeat(img, 3, axis=-1)  # Convert grayscale to 3-channel
    img = img / 255.0  # Normalize pixel values
    return img

# Step 2: Extract CNN Features using Pretrained Model
def extract_cnn_features(image, model):
    image_expanded = np.expand_dims(image, axis=0)  # Add batch dimension
    features = model.predict(image_expanded)
    return features.flatten()

# Load and preprocess image pairs
def load_image_pairs_with_split(image_dir, pairs_file, model, test_size=0.2, val_size=0.1):
    pairs = pd.read_csv(pairs_file)
    image_a, image_b, labels = [], [], []

    for idx, row in pairs.iterrows():
        print(f"Processing pair {idx + 1}/{len(pairs)}")
        img_a_path = os.path.join(image_dir, row["image_a"])
        img_b_path = os.path.join(image_dir, row["image_b"])

        img_a = preprocess_image(img_a_path)
        img_b = preprocess_image(img_b_path)

        cnn_a = extract_cnn_features(img_a, model)
        cnn_b = extract_cnn_features(img_b, model)

        image_a.append(cnn_a)
        image_b.append(cnn_b)
        labels.append(row["label"])

    image_a = np.array(image_a)
    image_b = np.array(image_b)
    labels = np.array(labels)

    X_train_a, X_temp_a, X_train_b, X_temp_b, y_train, y_temp = train_test_split(
        image_a, image_b, labels, test_size=test_size, random_state=42
    )
    val_split = val_size / (1 - test_size)
    X_val_a, X_test_a, X_val_b, X_test_b, y_val, y_test = train_test_split(
        X_temp_a, X_temp_b, y_temp, test_size=val_split, random_state=42
    )
    return X_train_a, X_train_b, y_train, X_val_a, X_val_b, y_val, X_test_a, X_test_b, y_test

# Step 3: Build Siamese Network
def siamese_network(input_shape):
    input_1 = Input(shape=input_shape)
    input_2 = Input(shape=input_shape)
    shared_dense = Dense(256, activation='relu')
    processed_1 = shared_dense(input_1)
    processed_2 = shared_dense(input_2)
    distance = Lambda(lambda tensors: K.abs(tensors[0] - tensors[1]))([processed_1, processed_2])
    output = Dense(1, activation='sigmoid')(distance)
    model = Model(inputs=[input_1, input_2], outputs=output)
    return model

# Load Pretrained CNN
vgg_model = VGG16(weights='imagenet', include_top=False)
cnn_feature_extractor = Model(inputs=vgg_model.input, outputs=Flatten()(vgg_model.output))

# Paths
image_dir = "/content/drive/MyDrive/Faria/fingerprint/dataset/2x extreme pair data"
pairs_file = "/content/drive/MyDrive/Faria/fingerprint/dataset/2x_extreme_fingerprint_pairs(geo_trans).csv"

# Load data
(
    X_train_a, X_train_b, y_train,
    X_val_a, X_val_b, y_val,
    X_test_a, X_test_b, y_test
) = load_image_pairs_with_split(image_dir, pairs_file, cnn_feature_extractor)

# Train Siamese Network
input_shape = X_train_a[0].shape
siamese_model = siamese_network(input_shape)
siamese_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])
checkpoint_path = "/content/drive/MyDrive/Faria/fingerprint/models/siamese_cnn_best.keras"
checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)

history = siamese_model.fit(
    [X_train_a, X_train_b], y_train,
    validation_data=([X_val_a, X_val_b], y_val),
    epochs=10,
    batch_size=32,
    callbacks=[checkpoint]
)

# Plot accuracy
plt.figure(figsize=(10, 5))
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy for CNN Feature EXtraction')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Evaluate model
siamese_model.load_weights(checkpoint_path)
test_loss, test_accuracy = siamese_model.evaluate([X_test_a, X_test_b], y_test)
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")

# Confusion Matrix
y_scores = siamese_model.predict([X_test_a, X_test_b]).ravel()
# Compute and display metrics
tar, far, eer, roc_auc = compute_metrics(y_test, y_scores)
y_pred = (y_scores >= 0.5).astype(int)
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Imposter", "Genuine"], yticklabels=["Imposter", "Genuine"])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

# Print classification report
print(classification_report(y_test, y_pred, target_names=["Imposter", "Genuine"]))

"""# **SIFT based Feature Extraction**"""

import os
import cv2
import numpy as np
import pandas as pd
import tensorflow as tf
from tensorflow.keras.models import Model
from tensorflow.keras.layers import Input, Dense, Lambda
from tensorflow.keras import backend as K
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler
from tensorflow.keras.callbacks import ModelCheckpoint
from sklearn.metrics import confusion_matrix, classification_report
import seaborn as sns
import matplotlib.pyplot as plt

# Step 1: Preprocess Image and Extract SIFT Features
def preprocess_image(image_path):
    sift = cv2.SIFT_create()
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    img = cv2.resize(img, (224, 224))
    img = cv2.convertScaleAbs(img, alpha=1.5, beta=0)
    keypoints, descriptors = sift.detectAndCompute(img, None)
    if descriptors is None:
        descriptors = np.zeros((1, 128))
    return descriptors

# Step 2: Combine SIFT Features
def combine_features(sift_features):
    sift_features_mean = np.mean(sift_features, axis=0)
    scaler = StandardScaler()
    sift_features_normalized = scaler.fit_transform([sift_features_mean])
    return sift_features_normalized.flatten()

def load_image_pairs_with_split(image_dir, pairs_file, test_size=0.2, val_size=0.1):
    pairs = pd.read_csv(pairs_file)
    image_a, image_b, labels = [], [], []

    for idx, row in pairs.iterrows():
        print(f"Processing pair {idx + 1}/{len(pairs)}")
        img_a_path = os.path.join(image_dir, row["image_a"])
        img_b_path = os.path.join(image_dir, row["image_b"])

        sift_a = preprocess_image(img_a_path)
        sift_b = preprocess_image(img_b_path)

        combined_a = combine_features(sift_a)
        combined_b = combine_features(sift_b)

        image_a.append(combined_a)
        image_b.append(combined_b)
        labels.append(row["label"])

    image_a = np.array(image_a)
    image_b = np.array(image_b)
    labels = np.array(labels)

    X_train_a, X_temp_a, X_train_b, X_temp_b, y_train, y_temp = train_test_split(
        image_a, image_b, labels, test_size=test_size, random_state=42
    )
    val_split = val_size / (1 - test_size)
    X_val_a, X_test_a, X_val_b, X_test_b, y_val, y_test = train_test_split(
        X_temp_a, X_temp_b, y_temp, test_size=val_split, random_state=42
    )

    return X_train_a, X_train_b, y_train, X_val_a, X_val_b, y_val, X_test_a, X_test_b, y_test

# Step 3: Build Siamese Network
def siamese_network(input_shape):
    input_1 = Input(shape=input_shape)
    input_2 = Input(shape=input_shape)
    shared_dense = Dense(256, activation='relu')
    processed_1 = shared_dense(input_1)
    processed_2 = shared_dense(input_2)
    distance = Lambda(lambda tensors: K.abs(tensors[0] - tensors[1]))([processed_1, processed_2])
    output = Dense(1, activation='sigmoid')(distance)
    model = Model(inputs=[input_1, input_2], outputs=output)
    return model

# Paths
image_dir = "/content/drive/MyDrive/Faria/fingerprint/dataset/pair_data_extreme(geo trans)"
pairs_file = "/content/drive/MyDrive/Faria/fingerprint/dataset/fingerprint_pairs_extreme(geo_trans).csv"

# Load and preprocess data
(X_train_a, X_train_b, y_train,
 X_val_a, X_val_b, y_val,
 X_test_a, X_test_b, y_test) = load_image_pairs_with_split(image_dir, pairs_file)

# Train Siamese Network
input_shape = X_train_a[0].shape
siamese_model = siamese_network(input_shape)
siamese_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

checkpoint_path = "/content/drive/MyDrive/Faria/fingerprint/models/feature_extraction_siamese_model_best.keras"
checkpoint = ModelCheckpoint(checkpoint_path, monitor='val_accuracy', save_best_only=True, mode='max', verbose=1)

history = siamese_model.fit([X_train_a, X_train_b], y_train,
                            validation_data=([X_val_a, X_val_b], y_val),
                            epochs=10, batch_size=32, callbacks=[checkpoint])

# Plot training and validation accuracy
plt.figure(figsize=(10, 5))
plt.plot(history.history['accuracy'], label='Train Accuracy')
plt.plot(history.history['val_accuracy'], label='Validation Accuracy')
plt.title('Training and Validation Accuracy')
plt.xlabel('Epochs')
plt.ylabel('Accuracy')
plt.legend()
plt.show()

# Evaluate
siamese_model.load_weights(checkpoint_path)
test_loss, test_accuracy = siamese_model.evaluate([X_test_a, X_test_b], y_test)
print(f"Test Accuracy: {test_accuracy * 100:.2f}%")

y_scores = siamese_model.predict([X_test_a, X_test_b]).ravel()
y_pred = (y_scores >= 0.5).astype(int)

# Compute confusion matrix
cm = confusion_matrix(y_test, y_pred)
plt.figure(figsize=(6, 5))
sns.heatmap(cm, annot=True, fmt="d", cmap="Blues", xticklabels=["Imposter", "Genuine"], yticklabels=["Imposter", "Genuine"])
plt.xlabel("Predicted")
plt.ylabel("Actual")
plt.title("Confusion Matrix")
plt.show()

# Print classification report
print(classification_report(y_test, y_pred, target_names=["Imposter", "Genuine"]))

"""# **Sift Feature Extraction**"""

import cv2
import os
import numpy as np
import pandas as pd
from google.colab.patches import cv2_imshow

# Load and preprocess images
def preprocess_image(image_path):
    sift = cv2.SIFT_create()
    img = cv2.imread(image_path, cv2.IMREAD_GRAYSCALE)
    img = cv2.resize(img, (224, 224))  # Resize to 224x224
    img = cv2.convertScaleAbs(img, alpha=1.5, beta=0) # Contrast control (1.0-3.0), Brightness control (0-100)
    # Detect key points and compute descriptors
    keypoints, descriptors = sift.detectAndCompute(img, None)
    # Draw key points on the image (optional for visualization)
    #img_with_keypoints = cv2.drawKeypoints(img, keypoints, None, color=(0, 255, 0), flags=cv2.DRAW_MATCHES_FLAGS_DEFAULT)
    img = img / 255.0  # Normalize pixel values
    #img = np.expand_dims(img, axis=-1)  # Add channel dimension
    #cv2_imshow(img)
    return img

# Load pairs
image_dir = "/content/drive/MyDrive/Faria/fingerprint/dataset/pair_data"
pairs = pd.read_csv("/content/drive/MyDrive/Faria/fingerprint/dataset/fingerprint_pairs.csv")
image_a = []
image_b = []
labels = []

for _, row in pairs.iterrows():
    img_a = preprocess_image(os.path.join(image_dir, row["image_a"]))
    img_b = preprocess_image(os.path.join(image_dir, row["image_b"]))
    image_a.append(img_a)
    image_b.append(img_b)
    labels.append(row["label"])

# Convert to numpy arrays
image_a = np.array(image_a)
image_b = np.array(image_b)
labels = np.array(labels)

from sklearn.model_selection import train_test_split

image_a_train, image_a_val, image_b_train, image_b_val, labels_train, labels_val = train_test_split(
    image_a, image_b, labels, test_size=0.2, random_state=42
)

import tensorflow as tf
from tensorflow.keras import layers, models
import numpy as np

# Define a Siamese Network

def build_siamese_network(input_shape):
    """Builds the Siamese network base model."""
    base_model = models.Sequential([
        layers.Conv2D(64, (3, 3), activation='relu', input_shape=input_shape),
        layers.MaxPooling2D((2, 2)),
        layers.Conv2D(128, (3, 3), activation='relu'),
        layers.MaxPooling2D((2, 2)),
        layers.Flatten(),
        layers.Dense(128, activation='relu'),
        layers.Dense(64, activation='relu')
    ])
    return base_model

# Define the inputs
input_shape = (128, 128, 1)  # Example fingerprint image size (128x128, grayscale)
input_a = layers.Input(shape=input_shape)
input_b = layers.Input(shape=input_shape)

# Build the base model
base_model = build_siamese_network(input_shape)

# Pass inputs through the base model
embedding_a = base_model(input_a)
embedding_b = base_model(input_b)

# Compute the L1 distance between the embeddings
l1_distance = layers.Lambda(lambda tensors: tf.abs(tensors[0] - tensors[1]))([embedding_a, embedding_b])

# Add a dense layer to predict similarity
output = layers.Dense(1, activation='sigmoid')(l1_distance)

# Build the complete Siamese Network
siamese_model = models.Model(inputs=[input_a, input_b], outputs=output)

# Compile the model
siamese_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])

# Summary of the model
siamese_model.summary()

# Example data (replace with actual fingerprint data)
# Assuming you have pairs of fingerprints and labels indicating whether they match
fingerprint_pairs = [
    (np.random.rand(128, 128, 1), np.random.rand(128, 128, 1)),  # Pair of fingerprints
    (np.random.rand(128, 128, 1), np.random.rand(128, 128, 1)),
]
labels = [1, 0]  # 1 for match, 0 for no match

# Preprocess the data
fingerprint_pairs = np.array(fingerprint_pairs)
fingerprint_pairs = np.expand_dims(fingerprint_pairs, axis=-1)  # Add channel dimension
labels = np.array(labels)

# Train the model
siamese_model.fit(
    [fingerprint_pairs[:, 0], fingerprint_pairs[:, 1]], labels,
    batch_size=2, epochs=10
)

# Save the model
siamese_model.save("siamese_fingerprint_model.h5")

# Evaluate the model (use a separate test dataset)
# test_pairs and test_labels should be prepared similarly to the training data
test_loss, test_accuracy = siamese_model.evaluate([test_pairs[:, 0], test_pairs[:, 1]], test_labels)
print(f"Test Loss: {test_loss}, Test Accuracy: {test_accuracy}")